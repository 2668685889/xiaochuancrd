#!/usr/bin/env python3
"""
æ™ºèƒ½åŠ©æ‰‹ç³»ç»Ÿç»¼åˆæ€§èƒ½æµ‹è¯•è„šæœ¬
æä¾›è¯¦ç»†çš„æ€§èƒ½åˆ†æå’Œä¼˜åŒ–å»ºè®®
"""

import asyncio
import time
import requests
import psutil
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
import json
import statistics
from typing import Dict, List, Any

class PerformanceAnalyzer:
    def __init__(self, base_url="http://localhost:8000"):
        self.base_url = base_url
        self.results = {}
        
    def check_service_availability(self) -> Dict[str, bool]:
        """æ£€æŸ¥å„ä¸ªæœåŠ¡çš„å¯ç”¨æ€§"""
        services = {
            "smart_assistant_info": "/api/v1/smart-assistant/info",
            "model_config": "/api/v1/model-config",
            "chat_history": "/api/v1/chat-history",
            "chat_endpoint": "/api/v1/smart-assistant/chat",
            "products": "/api/v1/products",
        }
        
        availability = {}
        for service_name, endpoint in services.items():
            try:
                response = requests.get(f"{self.base_url}{endpoint}", timeout=10)
                availability[service_name] = response.status_code == 200
                print(f"âœ… {service_name}: {'å¯ç”¨' if availability[service_name] else 'ä¸å¯ç”¨'}")
            except Exception as e:
                availability[service_name] = False
                print(f"âŒ {service_name}: è¿æ¥å¤±è´¥ - {e}")
        
        return availability
    
    def test_single_request(self, endpoint: str, payload: Dict = None) -> Dict[str, Any]:
        """æµ‹è¯•å•ä¸ªè¯·æ±‚çš„æ€§èƒ½"""
        start_time = time.time()
        try:
            if payload:
                response = requests.post(f"{self.base_url}{endpoint}", json=payload, timeout=30)
            else:
                response = requests.get(f"{self.base_url}{endpoint}", timeout=30)
            
            end_time = time.time()
            response_time = end_time - start_time
            
            return {
                "success": True,
                "status_code": response.status_code,
                "response_time": response_time,
                "response_size": len(response.content),
                "data": response.json() if response.status_code == 200 else None
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "response_time": time.time() - start_time
            }
    
    def test_concurrent_requests(self, endpoint: str, num_requests: int = 10, payload: Dict = None) -> Dict[str, Any]:
        """æµ‹è¯•å¹¶å‘è¯·æ±‚æ€§èƒ½"""
        print(f"ğŸš€ æµ‹è¯• {num_requests} ä¸ªå¹¶å‘è¯·æ±‚åˆ° {endpoint}")
        
        start_time = time.time()
        response_times = []
        success_count = 0
        
        def make_request(request_id):
            return self.test_single_request(endpoint, payload)
        
        with ThreadPoolExecutor(max_workers=min(num_requests, 20)) as executor:
            futures = [executor.submit(make_request, i) for i in range(num_requests)]
            
            for future in as_completed(futures):
                result = future.result()
                if result["success"]:
                    success_count += 1
                    response_times.append(result["response_time"])
        
        end_time = time.time()
        total_time = end_time - start_time
        
        if response_times:
            avg_response_time = statistics.mean(response_times)
            min_response_time = min(response_times)
            max_response_time = max(response_times)
            requests_per_second = success_count / total_time if total_time > 0 else 0
        else:
            avg_response_time = min_response_time = max_response_time = 0
            requests_per_second = 0
        
        return {
            "total_requests": num_requests,
            "successful_requests": success_count,
            "success_rate": success_count / num_requests if num_requests > 0 else 0,
            "total_time": total_time,
            "avg_response_time": avg_response_time,
            "min_response_time": min_response_time,
            "max_response_time": max_response_time,
            "requests_per_second": requests_per_second,
            "response_times": response_times
        }
    
    def get_system_resources(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ"""
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        # æŸ¥æ‰¾åç«¯è¿›ç¨‹
        backend_process = None
        for proc in psutil.process_iter(['pid', 'name', 'memory_percent', 'cpu_percent']):
            if 'python' in proc.info['name'].lower():
                try:
                    cmdline = ' '.join(proc.cmdline())
                    if 'run.py' in cmdline:
                        backend_process = proc
                        break
                except:
                    continue
        
        backend_info = {}
        if backend_process:
            backend_info = {
                "pid": backend_process.info['pid'],
                "memory_percent": backend_process.info['memory_percent'],
                "cpu_percent": backend_process.info['cpu_percent'],
                "memory_mb": backend_process.memory_info().rss / 1024 / 1024
            }
        
        return {
            "cpu_percent": cpu_percent,
            "memory": {
                "total_gb": memory.total / 1024 / 1024 / 1024,
                "used_gb": memory.used / 1024 / 1024 / 1024,
                "percent": memory.percent
            },
            "disk": {
                "total_gb": disk.total / 1024 / 1024 / 1024,
                "used_gb": disk.used / 1024 / 1024 / 1024,
                "percent": disk.percent
            },
            "backend_process": backend_info
        }
    
    def analyze_database_performance(self) -> Dict[str, Any]:
        """åˆ†ææ•°æ®åº“æ€§èƒ½"""
        # æµ‹è¯•æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½
        test_queries = [
            {"query": "è·å–äº§å“æ•°é‡", "endpoint": "/api/v1/products", "method": "GET"},
            {"query": "è·å–æ™ºèƒ½åŠ©æ‰‹ä¿¡æ¯", "endpoint": "/api/v1/smart-assistant/info", "method": "GET"},
        ]
        
        db_performance = {}
        for query_info in test_queries:
            result = self.test_single_request(query_info["endpoint"])
            db_performance[query_info["query"]] = result
        
        return db_performance
    
    def run_comprehensive_test(self) -> Dict[str, Any]:
        """è¿è¡Œç»¼åˆæ€§èƒ½æµ‹è¯•"""
        print("ğŸ”§ å¼€å§‹æ™ºèƒ½åŠ©æ‰‹ç³»ç»Ÿç»¼åˆæ€§èƒ½æµ‹è¯•")
        print("=" * 60)
        
        # 1. æ£€æŸ¥æœåŠ¡å¯ç”¨æ€§
        print("\n1. ğŸ“¡ æ£€æŸ¥æœåŠ¡å¯ç”¨æ€§")
        availability = self.check_service_availability()
        
        # 2. ç³»ç»Ÿèµ„æºæ£€æŸ¥
        print("\n2. ğŸ’» ç³»ç»Ÿèµ„æºæ£€æŸ¥")
        system_resources = self.get_system_resources()
        print(f"   CPUä½¿ç”¨ç‡: {system_resources['cpu_percent']}%")
        print(f"   å†…å­˜ä½¿ç”¨ç‡: {system_resources['memory']['percent']}%")
        print(f"   ç£ç›˜ä½¿ç”¨ç‡: {system_resources['disk']['percent']}%")
        
        if system_resources['backend_process']:
            print(f"   åç«¯è¿›ç¨‹å†…å­˜: {system_resources['backend_process']['memory_mb']:.1f}MB")
        
        # 3. å•è¯·æ±‚æ€§èƒ½æµ‹è¯•
        print("\n3. âš¡ å•è¯·æ±‚æ€§èƒ½æµ‹è¯•")
        single_request_results = {}
        
        # æµ‹è¯•æ™ºèƒ½åŠ©æ‰‹èŠå¤©
        chat_payload = {
            "message": "æŸ¥è¯¢æ‰€æœ‰äº§å“ä¿¡æ¯",
            "session_id": "performance_test_session"
        }
        
        chat_result = self.test_single_request("/api/v1/smart-assistant/chat", chat_payload)
        single_request_results["chat"] = chat_result
        
        if chat_result["success"]:
            print(f"   æ™ºèƒ½åŠ©æ‰‹èŠå¤©: {chat_result['response_time']:.3f}ç§’")
        else:
            print(f"   æ™ºèƒ½åŠ©æ‰‹èŠå¤©: å¤±è´¥ - {chat_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        # æµ‹è¯•äº§å“æŸ¥è¯¢
        products_result = self.test_single_request("/api/v1/products")
        single_request_results["products"] = products_result
        
        if products_result["success"]:
            print(f"   äº§å“æŸ¥è¯¢: {products_result['response_time']:.3f}ç§’")
        else:
            print(f"   äº§å“æŸ¥è¯¢: å¤±è´¥ - {products_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        # 4. å¹¶å‘æ€§èƒ½æµ‹è¯•
        print("\n4. ğŸ”¥ å¹¶å‘æ€§èƒ½æµ‹è¯•")
        concurrent_results = {}
        
        # å¹¶å‘èŠå¤©è¯·æ±‚æµ‹è¯•
        chat_concurrent = self.test_concurrent_requests(
            "/api/v1/smart-assistant/chat", 
            num_requests=5, 
            payload=chat_payload
        )
        concurrent_results["chat"] = chat_concurrent
        
        print(f"   å¹¶å‘èŠå¤©è¯·æ±‚:")
        print(f"     - æˆåŠŸç‡: {chat_concurrent['success_rate']*100:.1f}%")
        print(f"     - å¹³å‡å“åº”æ—¶é—´: {chat_concurrent['avg_response_time']:.3f}ç§’")
        print(f"     - ååé‡: {chat_concurrent['requests_per_second']:.1f} è¯·æ±‚/ç§’")
        
        # å¹¶å‘äº§å“æŸ¥è¯¢æµ‹è¯•
        products_concurrent = self.test_concurrent_requests("/api/v1/products", num_requests=10)
        concurrent_results["products"] = products_concurrent
        
        print(f"   å¹¶å‘äº§å“æŸ¥è¯¢:")
        print(f"     - æˆåŠŸç‡: {products_concurrent['success_rate']*100:.1f}%")
        print(f"     - å¹³å‡å“åº”æ—¶é—´: {products_concurrent['avg_response_time']:.3f}ç§’")
        print(f"     - ååé‡: {products_concurrent['requests_per_second']:.1f} è¯·æ±‚/ç§’")
        
        # 5. æ•°æ®åº“æ€§èƒ½åˆ†æ
        print("\n5. ğŸ—„ï¸ æ•°æ®åº“æ€§èƒ½åˆ†æ")
        db_performance = self.analyze_database_performance()
        
        # 6. ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
        print("\n6. ğŸ“Š æ€§èƒ½åˆ†ææŠ¥å‘Š")
        performance_report = self.generate_performance_report(
            availability, system_resources, single_request_results, concurrent_results, db_performance
        )
        
        return performance_report
    
    def generate_performance_report(self, availability, system_resources, single_results, concurrent_results, db_performance) -> Dict[str, Any]:
        """ç”Ÿæˆæ€§èƒ½åˆ†ææŠ¥å‘Š"""
        
        # è®¡ç®—æ€»ä½“è¯„åˆ†
        availability_score = sum(availability.values()) / len(availability) * 100
        
        # å“åº”æ—¶é—´è¯„åˆ†
        response_times = []
        for result in single_results.values():
            if result["success"]:
                response_times.append(result["response_time"])
        
        avg_response_time = statistics.mean(response_times) if response_times else 0
        response_time_score = max(0, 100 - (avg_response_time * 20))  # æ¯0.05ç§’æ‰£1åˆ†
        
        # å¹¶å‘æ€§èƒ½è¯„åˆ†
        success_rates = [result["success_rate"] for result in concurrent_results.values()]
        avg_success_rate = statistics.mean(success_rates) if success_rates else 0
        concurrency_score = avg_success_rate * 100
        
        # ç³»ç»Ÿèµ„æºè¯„åˆ†
        resource_score = max(0, 100 - system_resources["cpu_percent"] - system_resources["memory"]["percent"] / 2)
        
        # æ€»ä½“è¯„åˆ†
        overall_score = (availability_score + response_time_score + concurrency_score + resource_score) / 4
        
        # é—®é¢˜è¯†åˆ«
        issues = []
        
        if availability_score < 100:
            unavailable_services = [service for service, available in availability.items() if not available]
            issues.append(f"æœåŠ¡ä¸å¯ç”¨: {', '.join(unavailable_services)}")
        
        if avg_response_time > 1.0:
            issues.append(f"å“åº”æ—¶é—´è¿‡é•¿: {avg_response_time:.2f}ç§’")
        
        if avg_success_rate < 0.9:
            issues.append(f"å¹¶å‘æˆåŠŸç‡ä½: {avg_success_rate*100:.1f}%")
        
        if system_resources["cpu_percent"] > 80:
            issues.append(f"CPUä½¿ç”¨ç‡è¿‡é«˜: {system_resources['cpu_percent']}%")
        
        if system_resources["memory"]["percent"] > 80:
            issues.append(f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {system_resources['memory']['percent']}%")
        
        # ä¼˜åŒ–å»ºè®®
        recommendations = []
        
        if issues:
            if "æœåŠ¡ä¸å¯ç”¨" in str(issues):
                recommendations.append("æ£€æŸ¥æœåŠ¡é…ç½®å’Œæ•°æ®åº“è¿æ¥")
            if "å“åº”æ—¶é—´è¿‡é•¿" in str(issues):
                recommendations.append("ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢å’ŒAPIå“åº”")
            if "å¹¶å‘æˆåŠŸç‡ä½" in str(issues):
                recommendations.append("å¢åŠ æœåŠ¡å™¨èµ„æºå’Œä¼˜åŒ–å¹¶å‘å¤„ç†")
            if any("ä½¿ç”¨ç‡è¿‡é«˜" in issue for issue in issues):
                recommendations.append("ä¼˜åŒ–èµ„æºä½¿ç”¨å’Œè€ƒè™‘æ°´å¹³æ‰©å±•")
        else:
            recommendations.append("ç³»ç»Ÿæ€§èƒ½è‰¯å¥½ï¼Œç»§ç»­ä¿æŒç›‘æ§")
        
        report = {
            "timestamp": datetime.now().isoformat(),
            "overall_score": round(overall_score, 1),
            "availability_score": round(availability_score, 1),
            "response_time_score": round(response_time_score, 1),
            "concurrency_score": round(concurrency_score, 1),
            "resource_score": round(resource_score, 1),
            "availability": availability,
            "system_resources": system_resources,
            "single_request_results": single_results,
            "concurrent_results": concurrent_results,
            "db_performance": db_performance,
            "issues": issues,
            "recommendations": recommendations
        }
        
        # æ‰“å°æŠ¥å‘Šæ‘˜è¦
        print(f"\nğŸ“ˆ æ€§èƒ½è¯„åˆ†æ‘˜è¦:")
        print(f"   æ€»ä½“è¯„åˆ†: {report['overall_score']}/100")
        print(f"   å¯ç”¨æ€§: {report['availability_score']}/100")
        print(f"   å“åº”æ—¶é—´: {report['response_time_score']}/100")
        print(f"   å¹¶å‘æ€§èƒ½: {report['concurrency_score']}/100")
        print(f"   èµ„æºä½¿ç”¨: {report['resource_score']}/100")
        
        if issues:
            print(f"\nâš ï¸ å‘ç°çš„é—®é¢˜:")
            for issue in issues:
                print(f"   - {issue}")
        
        print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        for recommendation in recommendations:
            print(f"   - {recommendation}")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_filename = f"performance_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_filename}")
        
        return report

def main():
    """ä¸»å‡½æ•°"""
    analyzer = PerformanceAnalyzer()
    
    try:
        report = analyzer.run_comprehensive_test()
        
        # æ ¹æ®è¯„åˆ†ç»™å‡ºæœ€ç»ˆå»ºè®®
        print("\n" + "=" * 60)
        if report["overall_score"] >= 80:
            print("âœ… ç³»ç»Ÿæ€§èƒ½ä¼˜ç§€")
        elif report["overall_score"] >= 60:
            print("âš ï¸ ç³»ç»Ÿæ€§èƒ½è‰¯å¥½ï¼Œæœ‰ä¼˜åŒ–ç©ºé—´")
        else:
            print("âŒ ç³»ç»Ÿæ€§èƒ½éœ€è¦ä¼˜åŒ–")
        
    except Exception as e:
        print(f"âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    main()